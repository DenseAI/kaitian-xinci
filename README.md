# kaitian-xinci
开天-新词，中文新词发现与校对工具。

## 1 文本数据挖掘
[《互联网时代的社会语言学：基于SNS的文本数据挖掘》](http://www.matrix67.com/blog/archives/5044)，利用信息熵，直接从大规模的语料库中，自动发现可能成词的语言片段，从实际的效果看，还是非常不错。

前段时间，因项目需求，参考了上述文章，在一个领域提取新词，但发现效果不是很好，很多词虽然信息熵也很高，但看起意义不大，例如《西游记》的前20个词，如下：

```
Word,Length,Frequency,PMI,Entropy
与他,2,0.0005546631783803194,3.1409035351081536,3.958330498359802
在此,2,0.00036069137322419613,3.310849490919573,3.9348466612266737
唐僧,2,0.0013289473262349271,5.2020362931536415,3.875404224584528
在那里,3,0.00024527013379245337,3.8858135558017954,3.73102132123889
一个,2,0.0018082660844306367,3.059338241302599,3.7293382539389066
有些,2,0.0002677131525708478,3.417347201749542,3.665699647810152
妖魔,2,0.0002869500258094716,4.206171288435826,3.6131815221624484
甚么,2,0.0007662687840051812,5.395331594848622,3.610041531655062
这等,2,0.00040397433801109967,3.5505557771749863,3.4866527872657445
一条,2,0.00022443018778394426,3.76817632412436,3.4633977588845712
菩萨,2,0.0011125325023004094,6.774009869017439,3.4491040784694933
这般,2,0.00033985142721568704,4.42815730185858,3.417689753499862
天地,2,0.00011221509389197213,3.081712261764918,3.4133648186076755
不能,2,0.00030137768073843944,3.348931128920548,3.4043566892811232
老孙,2,0.0008480254952693322,4.555226892726218,3.40387251810055
不曾,2,0.0005129832863633012,3.7950182972410027,3.3716569019207845
在这里,3,0.00012023045774139872,4.174147692653218,3.3496256126847728
几个,2,0.00021962096947428833,3.387572001474773,3.3452425234306653
公主,2,0.000218017896704403,5.9289932607879985,3.343928327394668
吃了,2,0.0003494698638349989,3.2120581959510175,3.3265345260487127
```

比较明显的是“与他”，“在那里”，“在这里”，“吃了”，这些词，意义不大。

分析其中原因：
- 左右信息熵，例如“在”+“那里”也就是“在那里”，可能比“那里”的左信息熵还要大。

```
在那里,3,0.00024527013379245337,3.8858135558017954,3.73102132123889
那里,2,0.0010820741196725884,3.287673445887034,2.938950336460779
```

- 凝合程度，例如“在” + “那里”的聚合度，可能比“那” + “里”的聚合度还要大。

信息熵+凝合程度可以高效地刷选出候选新词，但候选新词是否有意义，需要通过其他方法进行二次刷选。

## 2 刷选有意义的新词
在自然语言中，词是由字组成，例如“在那里”，f(那里)=1是有意义的，f(在哪里)=0是没意义的，假设f()是判断某个候选词是否有意义的函数。

f()这个函数从哪里来？最快捷的方式是字典。假设字典里有“张三”这个词，但没有“李四”这个词，f()通过学习，知道 f(张三) = 1， 但 f(张三说) = 1，下次来了一个新句子包含“李四说”，那么，f()函数是否知道，f(李四) = 1， 而f(李四说) = 0？

我们通过学习 [bakeoff 2005](http://sighan.cs.uchicago.edu/bakeoff2005/) 中MSR训练的分词结果，例如 MSR训练集中有“云居寺”， f(云居寺) = 1，是否能够识别西游记中的“雷音寺” f(雷音寺) = 1?

```
信息熵+凝合程度，排在488位
雷音寺,3,5.129832863633012e-05,6.969841969546031,1.800869938848383
```

```
信息熵+凝合程度+f()，排在2位
雷音寺,3,5.120811136484019e-05,6.971602196411444,1.800869938848383,0.9994947910308838
```

《西游记》的前20个词，如下

```
Word,Length,Frequency,PMI,Entropy,Score
我们,2,0.0009457498067693922,3.9399445095182486,3.251112505242362,0.9997363686561584
雷音寺,3,5.120811136484019e-05,6.971602196411444,1.800869938848383,0.9994947910308838
一个,2,0.0018050859256106167,3.059040238420376,3.7293382539389066,0.9994857311248779
孙大圣,3,0.0002896458799073773,4.402813205088717,2.992242115653275,0.9994033575057983
一块,2,7.681216704726028e-05,3.862955388178667,2.6953645893519176,0.9992735385894775
两个,2,0.000806527753996233,4.065904538099362,3.0927117319494815,0.9992626905441284
一件,2,0.00010561672968998289,3.3203810660980957,3.224359042876477,0.9991719126701355
四十,2,0.00011361799709073918,3.897352933407198,2.5008111673719826,0.9991078972816467
怎么,2,0.001075370338661644,5.539534366910446,2.5988183908045164,0.9989941120147705
六十,2,6.240988572589899e-05,4.091023157214361,1.366450611825384,0.9989778995513916
没有,2,9.761546228922661e-05,3.0544774728082142,3.062282230516052,0.9989163875579834
起来,2,0.0003328527238714612,3.325203561266932,2.0332487572549516,0.9987279176712036
李天王,3,9.121444836862159e-05,5.544775861501283,2.9134177188682675,0.9986733198165894
自然,2,5.600887180529396e-05,3.5019067351612576,2.2878789313226564,0.9986352920532227
几年,2,5.600887180529396e-05,4.035457616736969,2.1627478372358686,0.9985302686691284
几个,2,0.00022083498026087333,3.3938927382697526,3.3319142430004884,0.9985171556472778
唐僧,2,0.0013314108954858449,5.202810313398271,3.8765048155407924,0.9985136985778809
千年,2,5.44086183251427e-05,4.074499792114159,2.9481019188839808,0.998407244682312
此间,2,0.00012962053189225173,3.7825532030679283,2.1811445141626047,0.9983642101287842
时间,2,7.201140660680652e-05,3.4207389456804966,1.4479183091144192,0.9983515739440918
```

能够有效地过滤掉类似“在这里”、“在那里”等意义不大的候选词。

这种方法拓展性比较强，如果觉得MSR的词汇量不够(约8.7万左右)，可以随时通过增加字典的方式，训练f()函数。

这种方法不是一点缺点也没有，例如 “取经”

```
取经,2,0.00036485779347448637,5.71485318922164,2.3223847703971217,0.4639596939086914
```

排到了468位，而在信息熵+凝合程度，排在301，经过分析，在MSR中，存在“争取经济稳定发展”，学到f(争取) = 1, 而 f(争取经) = 0，所以把 f(取经) 打的分数较低。

f() 算法在不断优化中......
 
## 3 参考
-[1] [互联网时代的社会语言学：基于SNS的文本数据挖掘](http://www.matrix67.com/blog/archives/5044)
-[2] [新词发现的信息熵方法与实现](https://kexue.fm/archives/3491)
-[3] [Chinese word segmentation algorithm without corpus（无需语料库的中文分词） ](https://github.com/Moonshile/ChineseWordSegmentation)
-[4] [新词发现算法(NewWordDetection) ](https://github.com/xylander23/New-Word-Detection)
-[5] ["新词发现"算法探讨与优化](https://zhuanlan.zhihu.com/p/80385615)
-[6] [kpot/keras-transformer](https://github.com/kpot/keras-transformer)
-[7] [GlassyWing/transformer-word-segmenter](https://github.com/GlassyWing/transformer-word-segmenter)


